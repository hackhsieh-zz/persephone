{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Functions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'YEAR', u'prodn_practice_desc_IRRIGATED',\n",
       "       u'prodn_practice_desc_NON-IRRIGATED',\n",
       "       u'prodn_practice_desc_NON-IRRIGATED, CONTINUOUS CROP',\n",
       "       u'prodn_practice_desc_NON-IRRIGATED, FOLLOWING SUMMER FALLOW',\n",
       "       u'prodn_practice_desc_NOT FOLLOWING ANOTHER CROP',\n",
       "       u'util_practice_desc_GRAIN', u'util_practice_desc_SILAGE',\n",
       "       u'util_practice_desc_SUGAR', u'YIELD/ACRE',\n",
       "       ...\n",
       "       u'COMMODITY_PEANUTS', u'COMMODITY_RICE', u'COMMODITY_RYE',\n",
       "       u'COMMODITY_SORGHUM', u'COMMODITY_SOYBEANS', u'COMMODITY_SUGARBEETS',\n",
       "       u'COMMODITY_SUGARCANE', u'COMMODITY_SUNFLOWER', u'COMMODITY_TOBACCO',\n",
       "       u'COMMODITY_WHEAT'],\n",
       "      dtype='object', length=836)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function 1:\n",
    "def fit_model_sklearn(df, commodity, model_name):\n",
    "    \"\"\"\n",
    "    INPUT: df (master dataframe); commodity (the type of commodity that one whishes to predict); mode_name (type of model)\n",
    "    OUT: model (the fitted modle); X_train; X_test; y_train; y_test \n",
    "    \"\"\"\n",
    "    com_df = df[df['COMMODITY']==commodity]\n",
    "    y, X = com_df['YIELD/ACRE'], com_df.drop(['COMMODITY', 'YIELD/ACRE'], axis=1)    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "                                     \n",
    "    if model_name == \"Linear Regression\":\n",
    "        model = LinearRegression()\n",
    "    elif model_name == 'RandomForestRegressor':\n",
    "        model = RandomForestRegressor(n_estimators=50)\n",
    "    elif model_name == 'ExtraTreesRegressor':\n",
    "        model = ExtraTreesRegressor(n_estimators=50)\n",
    "    elif model_name == 'GradientBoostingRegressor':\n",
    "        params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,'learning_rate': 0.01, 'loss': 'ls'}\n",
    "        model = GradientBoostingRegressor(**params)\n",
    "    model.fit(X_train, y_train) \n",
    "    return model, X_train, X_test, y_train, y_test\n",
    "\n",
    "#Function 2: \n",
    "def generate_sub_csv(df, commodity):\n",
    "    \"\"\"\n",
    "    INPUT: df (master dataframe); commodities_list (list of commodities)\n",
    "    \"\"\"\n",
    "    path = '/Users/Hsieh/Desktop/persephone/Data/Models/model_yield_{}.csv'\n",
    "    df[df['commodity_desc']==commodity].to_csv(path.format(commodity))\n",
    "        \n",
    "#Function 3: \n",
    "def join_dfs(weather_df, commodity):\n",
    "    path = '/Users/Hsieh/Desktop/persephone/Data/Models/model_yield_{}.csv'\n",
    "    yield_df = pd.read_csv('/Users/Hsieh/Desktop/persephone/Data/model_yield_{}.csv'.format(commodity))\n",
    "    \n",
    "#Function 4: \n",
    "def fit_model_sm(df, commodity, model_name):\n",
    "    \"\"\"\n",
    "    INPUT: df (master dataframe); commodity (the type of commodity that one whishes to predict); mode_name (type of model)\n",
    "    OUT: model (the fitted modle); X_train; X_test; y_train; y_test \n",
    "    \"\"\"\n",
    "    com_df = df[df[\"COMMODITY\"]==commodity]\n",
    "    y, X = com_df['YIELD/ACRE'], com_df.drop(['COMMODITY', 'YIELD/ACRE'], axis=1)    \n",
    "                                     \n",
    "    if model_name == \"Linear Regression\":\n",
    "        X = sm.add_constant(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        model = sm.OLS(y_train, X_train)\n",
    "        \n",
    "    results = model.fit()            \n",
    "    return model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Reorganizing Dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#declaring variables: \n",
    "targeted_states = pd.Series([\"California\", \"Iowa\", \"Texas\", \"Nebraska\", \"Illinois\",\\\n",
    "                  \"Minnesota\", \"Kansas\", \"Indiana\", \"North Carolina\", \"Wisconsin\"])\n",
    "targeted_states = targeted_states.apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) yield:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load yield_csv:\n",
    "yield_df = pd.read_csv('/Users/Hsieh/Desktop/persephone/Data/cleaned_master_yield.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_units = ['TONS / ACRE','LB / ACRE']\n",
    "yield_df = yield_df[yield_df[\"unit_desc\"].apply(lambda x: True if (x in target_units) else (False))]\n",
    "yield_df = yield_df[yield_df[\"unit_desc\"].notnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "out_put = ['value']\n",
    "group_columns = ['year','state_name','county_name','commodity_desc','unit_desc']\n",
    "dummy_columns = ['prodn_practice_desc','util_practice_desc','class_desc']\n",
    "drop_columns = ['Unnamed: 0','data_item','state_alpha','statisticcat_desc','asd_code','asd_desc',\\\n",
    "               'congr_district_code','county_ansi','county_code','location_desc']\n",
    "drop_extra = ['state_name','county_name','year']\n",
    "#drop unneeded columsn for yield/acre prediction: \n",
    "yield_df.sort(\"year\", ascending=True, inplace=True)\n",
    "yield_df.drop(drop_columns,axis=1,inplace=True)\n",
    "#yield_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yield_df['STATE'] = yield_df['state_name']\n",
    "yield_df['COUNTY'] = yield_df['county_name']\n",
    "yield_df['YEAR'] = yield_df['year']\n",
    "yield_df.drop(drop_extra,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commodities_list = yield_df.commodity_desc.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create  dummy variables:\n",
    "yield_df= pd.get_dummies(yield_df, columns=['prodn_practice_desc','util_practice_desc'],drop_first=True)\n",
    "#df_prodn = pd.get_dummies(yield_df['prodn_practice_desc'])\n",
    "#df_util_practice = pd.get_dummies(yield_df['util_practice_desc'])\n",
    "#df_class = pd.get_dummies(yield_df['class_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'commodity_desc', u'unit_desc', u'value', u'class_desc', u'STATE',\n",
       "       u'COUNTY', u'YEAR', u'prodn_practice_desc_IRRIGATED',\n",
       "       u'prodn_practice_desc_NON-IRRIGATED',\n",
       "       u'prodn_practice_desc_NON-IRRIGATED, CONTINUOUS CROP',\n",
       "       u'prodn_practice_desc_NON-IRRIGATED, FOLLOWING SUMMER FALLOW',\n",
       "       u'prodn_practice_desc_NOT FOLLOWING ANOTHER CROP',\n",
       "       u'util_practice_desc_GRAIN', u'util_practice_desc_SILAGE',\n",
       "       u'util_practice_desc_SUGAR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop variables that have already been dummified: \n",
    "yield_df.drop('class_desc',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TONS / ACRE    980303\n",
       "LB / ACRE       95807\n",
       "Name: unit_desc, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_df['unit_desc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yield_df['COMMODITY'] = yield_df['commodity_desc']\n",
    "yield_df['UNIT'] = yield_df['unit_desc']\n",
    "yield_df['YIELD/ACRE'] = yield_df['value']\n",
    "yield_df.drop(['commodity_desc','unit_desc','value'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yield_df.to_csv('/Users/Hsieh/Desktop/persephone/Data/model_yield_df_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commodities_list = yield_df['COMMODITY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate_sub_csv(yield_df, commodities_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) weather: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load weather csv:\n",
    "#weather_df = pd.read_csv('/Users/Hsieh/Desktop/persephone/Data/cleaned_master_weather.csv')\n",
    "weather_df = pd.read_csv('/Users/Hsieh/Desktop/persephone/Data/cleaned_master_weather_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#declaring variables: \n",
    "abnormal = -9999.00\n",
    "w_group_columns = ['STATE','COUNTY','YEAR','MONTH']\n",
    "\n",
    "features = ['CLDD','DPNP','DPNT','HTDD','DT90', 'DX32', 'DT00', 'DT32', 'DP01', 'DP05', 'DP10', 'MMXP',\\\n",
    "    'MMNP','TEVP','HO51A0','HO51P0','HO52A0','HO52P0','HO53A0','HO53P0','HO54A0','HO54P0','HO55A0','HO55P0',\\\n",
    "    'HO56A0','HO56P0','HO01A0','HO03A0','LO51A0','LO51P0','LO52A0','LO52P0','LO53A0','LO53P0','LO54A0','LO54P0',\\\n",
    "    'LO55A0','LO55P0','LO56A0','LO56P0','LO01A0','LO03A0','MO51A0','MO51P0','MO52A0','MO52P0','MO53A0','MO53P0',\\\n",
    "    'MO54A0','MO54P0', 'MO55A0','MO55P0','MO56A0','MO56P0','MO01A0','MO03A0','EMXP','MXSD','DSNW','TPCP','TSNW','EMXT',\\\n",
    "    'EMNT','MMXT','MMNT','MNTM','TWND']\n",
    "\n",
    "#order_columns = ['STATE','COUNTY', 'MONTH','DSNW','EMNT','EMXP','EMXT','MMNT','MMXT','MNTM','MXSD','TPCP','TSNW','YEAR']\n",
    "model_group_columns = ['STATE','COUNTY','YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop unneeded columns:\n",
    "weather_df.drop(['Unnamed: 0','LATITUDE','LONGITUDE'],axis=1,inplace=True)\n",
    "#grab monthly value:\n",
    "weather_df[\"MONTH\"] = weather_df[\"DATE\"].apply(lambda x: int(str(x)[4:6]))\n",
    "#turn -9999.00 (the way the data record Nan values) into Nan values:\n",
    "for feature in features: \n",
    "    weather_df[feature] = weather_df[feature].apply(lambda x: np.nan if (x == abnormal) else (x))\n",
    "#filter out a row where COUNTY value is missing: \n",
    "weather_df = weather_df[weather_df[\"COUNTY\"].notnull()==True]\n",
    "#capitalized 'STATE' and 'COUNTY':\n",
    "weather_df['STATE'] = weather_df['STATE'].apply(lambda x: x.upper())\n",
    "weather_df['COUNTY'] = weather_df['COUNTY'].apply(lambda x: x.upper())\n",
    "#drop unneeded columns: \n",
    "weather_df.drop('DATE',axis=1,inplace=True)\n",
    "#check total null values:\n",
    "#for c in weather_df:\n",
    "#    print c, np.mean(pd.isnull(weather_df[c]))\n",
    "#median weather data in respect to coutny/year:\n",
    "#median_weather_df = weather_df.groupby(w_group_columns).median().reset_index()\n",
    "#back fill na for values that is missing in median df:\n",
    "#median_weather_df.fillna(method=\"bfill\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average annual weather day: \n",
    "weather_df = weather_df.groupby(['STATE','COUNTY','YEAR']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df.drop(['MONTH'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop columns with more 30% na values:\n",
    "drop_features = []\n",
    "for c in weather_df:\n",
    "    if np.mean(pd.isnull(weather_df[c])) > 0.3:\n",
    "        drop_features.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df.drop(drop_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMXP', 'MMNP', 'TEVP', 'HO51A0', 'HO51P0', 'HO52A0', 'HO52P0', 'HO53A0', 'HO53P0', 'HO54A0', 'HO54P0', 'HO55A0', 'HO55P0', 'HO56A0', 'HO56P0', 'HO01A0', 'HO03A0', 'LO51A0', 'LO51P0', 'LO52A0', 'LO52P0', 'LO53A0', 'LO53P0', 'LO54A0', 'LO54P0', 'LO55A0', 'LO55P0', 'LO56A0', 'LO56P0', 'LO01A0', 'LO03A0', 'MO51A0', 'MO51P0', 'MO52A0', 'MO52P0', 'MO53A0', 'MO53P0', 'MO54A0', 'MO54P0', 'MO55A0', 'MO55P0', 'MO56A0', 'MO56P0', 'MO01A0', 'MO03A0', 'TWND']\n"
     ]
    }
   ],
   "source": [
    "print drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#since the df is order based on time and location this will fill the na with the values of next year. \n",
    "weather_df.fillna(method=\"bfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df.to_csv('/Users/Hsieh/Desktop/persephone/Data/model_weather_df_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Combining Dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weather_model_df = pd.read_csv('/Users/Hsieh/Desktop/persephone/Data/model_weather_df.csv')\n",
    "weather_model_df = pd.read_csv('/Users/Hsieh/Desktop/persephone/Data/model_weather_df_complete.csv')\n",
    "yield_model_df = pd.read_csv('/Users/Hsieh/Desktop/persephone/Data/model_yield_df_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df = pd.merge(left=yield_model_df, right=weather_model_df, left_on=['STATE','COUNTY','YEAR'],\\\n",
    "                   right_on=['STATE','COUNTY','YEAR'], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0_x', u'STATE', u'COUNTY', u'YEAR',\n",
       "       u'prodn_practice_desc_IRRIGATED', u'prodn_practice_desc_NON-IRRIGATED',\n",
       "       u'prodn_practice_desc_NON-IRRIGATED, CONTINUOUS CROP',\n",
       "       u'prodn_practice_desc_NON-IRRIGATED, FOLLOWING SUMMER FALLOW',\n",
       "       u'prodn_practice_desc_NOT FOLLOWING ANOTHER CROP',\n",
       "       u'util_practice_desc_GRAIN', u'util_practice_desc_SILAGE',\n",
       "       u'util_practice_desc_SUGAR', u'COMMODITY', u'UNIT', u'YIELD/ACRE',\n",
       "       u'Unnamed: 0_y', u'CLDD', u'DPNP', u'DPNT', u'HTDD', u'DT90', u'DX32',\n",
       "       u'DT00', u'DT32', u'DP01', u'DP05', u'DP10', u'EMXP', u'MXSD', u'DSNW',\n",
       "       u'TPCP', u'TSNW', u'EMXT', u'EMNT', u'MMXT', u'MMNT', u'MNTM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df.drop(['Unnamed: 0_x','Unnamed: 0_y','UNIT'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grouping column names: \n",
    "categorical_features = ['STATE','COUNTY',]\n",
    "dependent_variable = ['YIELD/ACRE']\n",
    "#get dummy variables for categorical variables:\n",
    "model_df= pd.get_dummies(model_df, columns=categorical_features,drop_first=True)\n",
    "model_df.to_csv('/Users/Hsieh/Desktop/persephone/Data/model_df_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Features Engineering: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI: Models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#after cleanning, some commodities has no values (removing these commodities)\n",
    "commodities_list = list(commodities_list)\n",
    "commodities_list.remove('SAFFLOWER')\n",
    "commodities_list.remove('MUSTARD')\n",
    "commodities_list.remove('LENTILS')\n",
    "commodities_list.remove('PEAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a: RandomForestRegressor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RandomForestRegression:\n",
    "#model, X_train, X_test, y_train, y_test = fit_model_sklearn(model_df, \"MUSTARD\", \"RandomForestRegressor\")\n",
    "#predict = model.predict(X_test)\n",
    "#print r2_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************\n",
      "WHEAT's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.911247406595\n",
      "****************************************************************************\n",
      "HAY's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.29154540912\n",
      "****************************************************************************\n",
      "CORN's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.878642694583\n",
      "****************************************************************************\n",
      "OATS's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.629691443376\n",
      "****************************************************************************\n",
      "BARLEY's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.592831648257\n",
      "****************************************************************************\n",
      "TOBACCO's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.300607453061\n",
      "****************************************************************************\n",
      "SOYBEANS's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.76963845514\n",
      "****************************************************************************\n",
      "COTTON's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.793412271758\n",
      "****************************************************************************\n",
      "SORGHUM's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.767053748398\n",
      "****************************************************************************\n",
      "RICE's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.744196001234\n",
      "****************************************************************************\n",
      "PEANUTS's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.7717680733\n",
      "****************************************************************************\n",
      "BEANS's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.422356165067\n",
      "****************************************************************************\n",
      "SUGARBEETS's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.759535904259\n",
      "****************************************************************************\n",
      "RYE's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.504906424855\n",
      "****************************************************************************\n",
      "FLAXSEED's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.498002018821\n",
      "****************************************************************************\n",
      "SUNFLOWER's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.620512461127\n",
      "****************************************************************************\n",
      "SUGARCANE's adjusted r^2 score with RandomForestRegressoris:\n",
      "0.6469138058\n",
      "****************************************************************************\n",
      "CANOLA's adjusted r^2 score with RandomForestRegressoris:\n",
      "-0.264862452485\n"
     ]
    }
   ],
   "source": [
    "#results for all commodities:\n",
    "for commodity in commodities_list: \n",
    "    model, X_train, X_test, y_train, y_test = fit_model_sklearn(model_df, commodity, \"RandomForestRegressor\")\n",
    "    predict = model.predict(X_test)\n",
    "    print \"****************************************************************************\"\n",
    "    print \"{}'s adjusted r^2 score with {} is:\".format(commodity,\"RandomForestRegressor\")\n",
    "    print r2_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## b: Linear Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) w/ Sklearn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fitting: \n",
    "#model, X_train, X_test, y_train, y_test = fit_model_sklearn(model_df, \"BARLEY\", \"Linear Regression\")\n",
    "#predict = model.predict(X_test)\n",
    "#print r2_score(y_test, predict)\n",
    "#scoring: \n",
    "#print r2_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) w/ Stats Models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fitting: \n",
    "#model, X_train, X_test, y_train, y_test = fit_model_sm(model_df, \"BARLEY\", \"Linear Regression\"):\n",
    "#y_predict = results.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scoring: \n",
    "#print results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (85692,818) and (42207,818) not aligned: 818 (dim 1) != 42207 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-e438c5300cc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#for commodity in commodities_list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model_sm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommodity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Linear Regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#    print \"****************************************************************************\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#    print \"{}'s adjusted r^2 score with {} is:\".format(commodity,\"Linear Regression\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/statsmodels/regression/linear_model.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, params, exog)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (85692,818) and (42207,818) not aligned: 818 (dim 1) != 42207 (dim 0)"
     ]
    }
   ],
   "source": [
    "#results for all commodities:\n",
    "#for commodity in commodities_list: \n",
    "model, X_train, X_test, y_train, y_test = fit_model_sm(model_df, commodity, \"Linear Regression\")\n",
    "predict = model.predict(X_test)\n",
    "#    print \"****************************************************************************\"\n",
    "#    print \"{}'s adjusted r^2 score with {} is:\".format(commodity,\"Linear Regression\")\n",
    "#    print results.summary()\n",
    "#    print r2_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c: ExtraTreesRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************\n",
      "WHEAT's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.924089785802\n",
      "****************************************************************************\n",
      "HAY's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.151869505068\n",
      "****************************************************************************\n",
      "CORN's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.899585625326\n",
      "****************************************************************************\n",
      "OATS's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.67552886568\n",
      "****************************************************************************\n",
      "BARLEY's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.631318013723\n",
      "****************************************************************************\n",
      "TOBACCO's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.386825483183\n",
      "****************************************************************************\n",
      "SOYBEANS's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.810036598792\n",
      "****************************************************************************\n",
      "COTTON's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.812180946764\n",
      "****************************************************************************\n",
      "SORGHUM's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.799016233593\n",
      "****************************************************************************\n",
      "RICE's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.751517918608\n",
      "****************************************************************************\n",
      "PEANUTS's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.812578671946\n",
      "****************************************************************************\n",
      "BEANS's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.34767309177\n",
      "****************************************************************************\n",
      "SUGARBEETS's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.788267407932\n",
      "****************************************************************************\n",
      "RYE's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.481234673616\n",
      "****************************************************************************\n",
      "FLAXSEED's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.509085441391\n",
      "****************************************************************************\n",
      "SUNFLOWER's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.595991029196\n",
      "****************************************************************************\n",
      "SUGARCANE's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.670403236977\n",
      "****************************************************************************\n",
      "CANOLA's adjusted r^2 score with ExtraTreesRegressor is:\n",
      "0.122954447779\n"
     ]
    }
   ],
   "source": [
    "#results for all commodities:\n",
    "for commodity in commodities_list: \n",
    "    model, X_train, X_test, y_train, y_test = fit_model_sklearn(model_df, commodity, \"ExtraTreesRegressor\")\n",
    "    predict = model.predict(X_test)\n",
    "    print \"****************************************************************************\"\n",
    "    print \"{}'s adjusted r^2 score with {} is:\".format(commodity,\"ExtraTreesRegressor\")\n",
    "    print r2_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d: Gradient Boosting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results for all commodities:\n",
    "#for commodity in commodities_list: \n",
    "#    model, X_train, X_test, y_train, y_test = fit_model_sklearn(model_df, commodity, \"GradientBoostingRegressor\")\n",
    "#    predict = model.predict(X_test)\n",
    "#    print \"****************************************************************************\"\n",
    "#    print \"{}'s adjusted r^2 score with {} is:\".format(commodity,\"GradientBoostingRegressor\")\n",
    "#    print r2_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI: Grid Search: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a): Linear Regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Random Forest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Gradient Boosting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VII: Score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VIII: Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function 1: \n",
    "\"\"\"\n",
    "def merge_cols(x):\n",
    "    return x['COUNTY'] + x['STATE'] + str(x['MONTH'])\n",
    "\"\"\"\n",
    "\n",
    "#Function 2: \n",
    "\"\"\"\n",
    "def fill_na(x, median_df):\n",
    "    INPUT: x (pd series; row of a df); median_df (pd df; dataframe with the needed average values)\n",
    "    OUTPUT: new_x (pd series; new row of df with filled_na values)\n",
    "    OVERVIEW: fill in na values of a df with historical average of the monthly value of that month and region \n",
    "    \n",
    "    state, county, month = x[0], x[1], x[2]  \n",
    "    \n",
    "    row = median_df.loc[(median_df['STATE']==state)&(median_df['COUNTY']==county)&(median_df['MONTH']==month)]\n",
    "    s_row = row.iloc[0][1:]  \n",
    "    \n",
    "    x.loc[np.where(x==\"NAN\")] = s_row.loc[np.where(x==\"NAN\")]\n",
    "    return x \n",
    "\"\"\"\n",
    "#model_df.unit_desc.unique()\n",
    "\n",
    "#grouping column names: \n",
    "#categorical_features = ['STATE','COUNTY']\n",
    "#numeric_features = ['YEAR','DSNW','EMNT','EMXP','EMXT','MMNT','MMXT','MNTM','MXSD','TPCP','TSNW']\n",
    "#dependent_variable = ['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Key: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_key = {'CLDD':'Cooling degree days','DPNP':'Departure from normal monthly precipitation',\\\n",
    "               'DPNT':'Departure from normal monthly temperature','HTDD':'Heating degree days',\\\n",
    "                'DT90':'Number days with maximum temperature greater than or equal 90.0 F',\\\n",
    "                'DX32':'Number days with maximum temperature less than or equal to 32.0 F',\\\n",
    "                'DT00':'Number days with minimum temperature less than or equal to 0.0 F',\\\n",
    "                'DT32':'Number days with minimum temperature less than or equal to 32.0 F',\\\n",
    "                'DP01':'Number of days with greater than or equal to 0.1 inch of precipitation',\\\n",
    "                'DP05':'Number of days with greater than or equal to 0.5 inch of precipitation',\\\n",
    "                'DP10':'Number of days with greater than or equal to 1.0 inch of precipitation',\\\n",
    "                'MMXP':'Monthly mean maximum temperature of evaporation pan water',\\\n",
    "                'MMNP':'Monthly mean maximum temperature of evaporation pan water',\\\n",
    "                'TEVP':'Total monthly evaporation',\\\n",
    "                'EMXP':'Extreme maximum daily precipitation','MXSD':'Maximum snow depth',\\\n",
    "                'DSNW':'Number days with snow depth > 1 inch','TPCP':'Total precipitation',\\\n",
    "                'TPCP':'Total precipitation','TSNW':'Total snow fall',\\\n",
    "                'EMXT':'Extreme maximum daily temperature','EMNT':'Extreme maximum daily temperature',\\\n",
    "                'EMNT':'Extreme minimum daily temperature','MMXT':'Monthly Mean maximum temperature',\\\n",
    "                'MMNT':'Monthly Mean minimum temperature','MNTM':' Monthly mean temperature',\\\n",
    "                'TWND':'Total monthly wind movement over evaporation pan'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
